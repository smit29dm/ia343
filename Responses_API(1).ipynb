{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86832346-9e59-4811-83ff-04e2e007e515",
   "metadata": {},
   "source": [
    "# OpenAI Responses API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ea36b9-4484-4e95-a023-41e475f1af58",
   "metadata": {},
   "source": [
    "## What is the OpenAI Responses API?\n",
    "\n",
    "The Responses API is a new API released in March 2025. It is a combination of the traditional \n",
    "Chat Completions API and the Assistants API, providing support for:\n",
    "\n",
    "- **Traditional Chat Completions:** Facilitates seamless conversational AI experiences.\n",
    "- **Web Search:** Enables real-time information retrieval from the internet.\n",
    "- **File Search:** Allows searching within files for relevant data.\n",
    "\n",
    "Accordingly, the Assistants API will be retired in 2026. \n",
    "\n",
    "> **For new users, OpenAI recommends using the Responses API instead of the Chat Completions API to leverage its expanded capabilities.**\n",
    "\n",
    "For a comprehensive comparison between the Responses API and the Chat Completions API, refer to the official OpenAI documentation: \n",
    "[Responses vs. Chat Completions](https://platform.openai.com/docs/guides/responses-vs-chat-completions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3ae0b6-d8f5-4547-be96-bafdf768853c",
   "metadata": {},
   "source": [
    "## Summary of This Notebook\n",
    "This notebook provides a hands-on guide for using the **OpenAI Responses API** to analyze tweets. \n",
    "It covers essential techniques such as:\n",
    "\n",
    "- **Creating a vector store** and uploading tweets for semantic search.\n",
    "- **Using file search** to analyze private datasets.\n",
    "- **Performing a web search** to retrieve the latest public information.\n",
    "- **Utilizing stateful responses** to maintain conversation context.\n",
    "- **Combining file and web search** to enhance retrieval-augmented generation (RAG) applications.\n",
    "\n",
    "By the end of this notebook, users will be able to integrate OpenAI's Responses API for efficient data retrieval and analysis of structured and unstructured data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbe454d-ac76-413a-b17c-f79c4873e9df",
   "metadata": {},
   "source": [
    "## Install Required Libraries\n",
    "To use the OpenAI Responses API, we need to install the following libraries:\n",
    "\n",
    "- **`openai`**: Provides access to OpenAI's APIs, including the Responses API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6346923a-a409-4621-a6fc-d0f72dccde48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9706b93-af03-4f7a-89bd-6649b11ba83c",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a4f25ea-3dc7-4955-8589-0527ce749a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818d0310-abab-49d2-9d7e-69c92112efd5",
   "metadata": {},
   "source": [
    "## Retrieve Secrets from AWS Secrets Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28c8e717-0cbb-4125-8a3e-9ea5f1c92180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        raise e\n",
    "\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "    \n",
    "    return json.loads(secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bbd9ff-e0bc-4ec0-9fbc-b2f931defe4e",
   "metadata": {},
   "source": [
    "## Initialize OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ec97cf0-736c-439e-81e4-0d22a7b527bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "openai_api_key  = get_secret('openai')['api_key']\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef03684-10fa-433c-a9ff-5f322fd215c3",
   "metadata": {},
   "source": [
    "## File Search API\n",
    "\n",
    "### Introduction to File Search\n",
    "File search API enables efficient retrieval of relevant information \n",
    "from uploaded files by leveraging vector-based indexing. This feature is particularly useful \n",
    "for searching large datasets, extracting insights, and improving retrieval-augmented generation (RAG) applications.\n",
    "\n",
    "Unlike traditional keyword-based searches, the Responses API uses embeddings \n",
    "to identify semantically relevant content, making it ideal for analyzing structured \n",
    "and unstructured text data (OpenAI, 2025).\n",
    "\n",
    "For more details, visit the official OpenAI documentation: \n",
    "[File Search in Responses API](https://platform.openai.com/docs/guides/tools-file-search)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12034ce9-04cc-4f03-8573-9328f05c3735",
   "metadata": {},
   "source": [
    "### Create a Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2e24f19-be80-429e-8a9a-ece1da9a4ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs_691263fce7308191a5eda682ae982c96\n"
     ]
    }
   ],
   "source": [
    "vector_store = client.vector_stores.create(\n",
    "    name=\"my_vector_store\"\n",
    ")\n",
    "vector_store_id = vector_store.id\n",
    "print(vector_store_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e80e5ee-4317-4317-8e46-493c3f5d2e95",
   "metadata": {},
   "source": [
    "### Upload Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "596ecef7-0b1a-4cbe-8e47-f7e13d6d6150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-A8LN3MwsAMNztvMiy7Czd4\n"
     ]
    }
   ],
   "source": [
    "with open('tweet_text.json', 'rb') as f:\n",
    "    file = client.files.create(\n",
    "        file=f,            # file-like object\n",
    "        purpose=\"assistants\"\n",
    "    )\n",
    "\n",
    "file_id = file.id\n",
    "print(file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4c9ed-7b16-4178-914e-a4436b6d2971",
   "metadata": {},
   "source": [
    "### Attach File to Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15874314-ed04-4315-85cc-e9ce4eee9d73",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-A8LN3MwsAMNztvMiy7Czd4\n"
     ]
    }
   ],
   "source": [
    "attach_status =client.vector_stores.files.create(\n",
    "    vector_store_id=vector_store_id,\n",
    "    file_id=file_id\n",
    "            )\n",
    "\n",
    "print(attach_status.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091a9cf3-a802-41a1-9707-e04ee1bdfd8f",
   "metadata": {},
   "source": [
    "### Query the Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf3753c0-b763-403d-be6a-368d80f6714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"the latest development in generativeAI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c757b4d8-d603-4b01-a610-978b9cfa5010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They have been VERY clear that Chatgpt, these AI videos‚Ä¶\"\n",
      "  }\n",
      "},\n",
      "{\n",
      "  \"_id\": {\n",
      "    \"$oid\": \"68e56b1e1\n",
      " Relevant score: 0.6760340526672118\n",
      "They have been VERY clear that Chatgpt, these AI videos‚Ä¶\"\n",
      "  }\n",
      "},\n",
      "{\n",
      "  \"_id\": {\n",
      "    \"$oid\": \"68e56b1f1\n",
      " Relevant score: 0.6010846063542131\n",
      "Learning Plans. Use coupon code ùêíùêèùêãùüëùüé at checkout.üéØ\\n\\nJoin Now üëâ https://t.co/LS2JuCrVmz\\n\\n#AI #Ce\n",
      " Relevant score: 0.5987929345462765\n",
      "Create stunning, cinematic videos from a prompt‚Äînow with audio, physics, and cameos. One prompt = en\n",
      " Relevant score: 0.5911156596667607\n",
      "They have been VERY clear that Chatgpt, these AI videos‚Ä¶\"\n",
      "  }\n",
      "},\n",
      "{\n",
      "  \"_id\": {\n",
      "    \"$oid\": \"68e56b1d1\n",
      " Relevant score: 0.5630078302657743\n"
     ]
    }
   ],
   "source": [
    "search_results = client.vector_stores.search(\n",
    "    vector_store_id=vector_store_id,\n",
    "    query=query\n",
    ")\n",
    "\n",
    "for result in search_results.data[:5]:\n",
    "    print(result.content[0].text[:100] + '\\n Relevant score: ' + str(result.score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d89abc-a919-4563-9f06-8dfc9410a4ab",
   "metadata": {},
   "source": [
    "## OpenAI Response API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee1ecaa-6836-41d5-847e-853b62bcdd0b",
   "metadata": {},
   "source": [
    "### Simple Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e96e622-9b8c-47d5-9a4a-3c3e6315b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_response = client.responses.create(\n",
    "  model=\"gpt-4o\",\n",
    "  input=[\n",
    "      {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": query\n",
    "      }\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1c7e17d-a20d-40e2-b1bc-ee30f9199627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "As of the latest updates in 2023, several key developments in generative AI are worth noting:\n",
       "\n",
       "1. **Multimodal Models**: There has been significant progress in multimodal AI systems that can understand and generate text, images, audio, and video simultaneously. These models are becoming more integrated, allowing for seamless transitions and understanding across different types of media.\n",
       "\n",
       "2. **More Efficient Training**: Researchers have been focusing on reducing the resources required to train large AI models. This includes advancements in sparse models, where only parts of the network are activated at a time, reducing computation costs.\n",
       "\n",
       "3. **Improved Text Understanding and Generation**: Language models, like GPT-4 and its successors, have become even more sophisticated in generating contextually relevant and coherent text. This includes better handling of nuanced tasks like complex reasoning and detailed summarization.\n",
       "\n",
       "4. **Applications in Creative Fields**: Generative AI is being increasingly used in art, music, and design, with tools that assist artists in creating novel works or enhancing creativity. These applications allow for more interactive and dynamic collaboration between humans and AI.\n",
       "\n",
       "5. **Ethical and Responsible AI**: There is a growing emphasis on developing AI responsibly, with more research into bias mitigation, transparency, and accountability in generative AI systems. Many organizations are publishing guidelines and frameworks to ensure ethical AI usage.\n",
       "\n",
       "6. **Customized AI Solutions**: Tailoring AI models for specific industries or businesses is becoming more common. These specialized models are trained on domain-specific data, offering more relevant insights and solutions.\n",
       "\n",
       "7. **Advancements in Large Language Models (LLMs)**: Larger and more capable LLMs are being released, with enhanced capabilities in understanding context and maintaining coherent long-form conversations.\n",
       "\n",
       "These developments are rapidly evolving, and ongoing research continues to push the boundaries of what generative AI can achieve."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(simple_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b468693-2250-4b09-994e-2eb52b1d5741",
   "metadata": {},
   "source": [
    "### File Search Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4061d68-56f6-4dfc-974c-b2446ad79ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_search_response = client.responses.create(\n",
    "    input= query,\n",
    "    model=\"gpt-4o\",\n",
    "    temperature = 0,\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store_id],\n",
    "    }]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d448b96-b931-4af8-bd71-1f8facd44ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The latest developments in generative AI include several exciting advancements:\n",
       "\n",
       "1. **OpenAI's Sora2**: This tool allows users to create cinematic videos from a prompt, now with added features like audio, physics, and cameos.\n",
       "\n",
       "2. **Generative AI in Creative Industries**: AI is transforming creative fields by enabling the creation of content such as videos and music without traditional production resources.\n",
       "\n",
       "3. **AI in Finance**: Generative AI is being used for chatbots, instant loan scoring, fraud detection, and robo-advisors, revolutionizing the finance sector.\n",
       "\n",
       "4. **AI in Healthcare**: Generative AI is supporting doctors with data interpretation and preliminary analysis, enhancing patient care.\n",
       "\n",
       "5. **AI in Marketing**: Generative AI is changing content marketing workflows, reducing costs, and improving results.\n",
       "\n",
       "These developments highlight the diverse applications and transformative potential of generative AI across various industries."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(file_search_response.output_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddd7ddc-64d0-49dc-a0f7-c24a4a1b8c31",
   "metadata": {},
   "source": [
    "## Web Search API\n",
    "\n",
    "### Introduction to Web Search\n",
    "The OpenAI Web Search tool allows models to retrieve real-time information from the internet. \n",
    "This capability is particularly useful for obtaining up-to-date data, fact-checking, and expanding knowledge \n",
    "without relying solely on pre-trained information. \n",
    "\n",
    "By leveraging OpenAI's web search functionality, the Responses API can fetch external data \n",
    "and provide accurate, relevant results in real time (OpenAI, 2025). \n",
    "This feature enhances applications that require the latest insights, such as news aggregation, research, \n",
    "or dynamic content generation.\n",
    "\n",
    "For more details, visit the official OpenAI documentation: \n",
    "[Web Search in Responses API](https://platform.openai.com/docs/guides/tools-web-search)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f2bc7e-9a56-4695-8148-915d875ad716",
   "metadata": {},
   "source": [
    "### Perform Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "455aae40-d752-4e05-b8b6-da213e9b1f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search_response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input= query,\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1f5d2c4-f2fb-4261-bc7e-f5b5924f9959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here‚Äôs a comprehensive, up-to-date overview of the **latest developments in generative AI as of November 10, 2025**, structured into key themes and innovations. This detailed summary exceeds 700 words and includes multiple citations per paragraph.\n",
       "\n",
       "---\n",
       "\n",
       "##  1. New Model Releases & Innovations\n",
       "\n",
       "- **OpenAI‚Äôs GPT‚Äë5 (Launched August 7, 2025)**  \n",
       "  OpenAI released GPT‚Äë5, a sophisticated multimodal foundation model, on August 7, 2025. It became accessible through ChatGPT, Microsoft Copilot, and the OpenAI API. The system features multiple internal models‚Äîfast (‚Äúmain‚Äù and ‚Äúmain‚Äëmini‚Äù), reasoning (‚Äúthinking‚Äù and ‚Äúthinking‚Äëmini‚Äù), and even a ‚Äúthinking‚Äënano‚Äù version for efficiency. A real-time router dynamically assigns tasks to the appropriate model, enhancing adaptability and performance. GPT‚Äë5 also brought agentic capabilities, such as autonomous desktop setups and web browsing to execute tasks.([en.wikipedia.org](https://en.wikipedia.org/wiki/GPT-5?utm_source=openai))\n",
       "\n",
       "- **OpenAI‚Äôs o4‚Äëmini (Released April 16, 2025)**  \n",
       "  Prior to GPT‚Äë5, OpenAI introduced o4‚Äëmini (and an enhanced ‚Äúhigh‚Äù version) on April 16, 2025. These models support both text and image inputs, enabling analysis of whiteboard sketches and performing chain-of-thought reasoning. The high variant trades speed for accuracy. Applications span forecasting, healthcare diagnostics, and financial compliance.([en.wikipedia.org](https://en.wikipedia.org/wiki/OpenAI_o4-mini?utm_source=openai))\n",
       "\n",
       "- **Open-Weight Models: gpt‚Äëoss‚Äë20b and gpt‚Äëoss‚Äë120b (Released August 2025)**  \n",
       "  In a landmark move, OpenAI unveiled its first open-weight models since GPT‚Äë2: gpt‚Äëoss‚Äë20b and gpt‚Äëoss‚Äë120b. These text-based models support chain-of-thought reasoning and are compatible with local hardware. gpt‚Äëoss‚Äë20b can run on consumer PCs with Snapdragon processors or NVIDIA GPUs, barely needing powerful cloud infrastructure. The heavier gpt‚Äëoss‚Äë120b requires robust hardware (like RTX PRO). These models are accessible via platforms such as Hugging Face and Ollama.([windowscentral.com](https://www.windowscentral.com/artificial-intelligence/openai-chatgpt/openai-launches-two-gpt-models-theyre-not-gpt-5-but-they-run-locally-on-snapdragon-pcs-and-nvidia-rtx-gpus?utm_source=openai))\n",
       "\n",
       "- **Alibaba‚Äôs Qwen Model Family (Latest: Qwen3‚ÄëNext and Qwen3‚ÄëOmni in September 2025; Thinking Mode in early November)**  \n",
       "  Alibaba‚Äôs Qwen series has seen rapid expansion. In September 2025, the company released Qwen3‚ÄëNext (augmented with hybrid attention, MoE architecture, and multi-token prediction) and Qwen3‚ÄëOmni, a capable multimodal model handling text, images, audio, and video. Qwen3‚ÄëMax preceded them (September 5), but ‚Äúthinking mode‚Äù for deeper reasoning became publicly available in early November 2025.([en.wikipedia.org](https://en.wikipedia.org/wiki/Qwen?utm_source=openai))\n",
       "\n",
       "- **Google DeepMind‚Äôs Nano Banana (\"Gemini 2.5 Flash Image\") (Released August 26, 2025)**  \n",
       "  Google‚Äôs image generation tool, nickname ‚ÄúNano Banana,‚Äù officially Gemini 2.5 Flash Image, launched August 26, 2025. Known for creating photorealistic ‚Äú3D figurine‚Äù styles, it allows editing like hairstyle or backdrop changes with consistency and embedded SynthID watermarking. Integrated into Gemini app, Google AI Studio, and Vertex AI, it surged adoption‚Äîattracting over 10 million new users and handling more than 200 million edits in its initial weeks.([en.wikipedia.org](https://en.wikipedia.org/wiki/Nano_Banana?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "##  2. Generative AI in Video & 3D Worlds\n",
       "\n",
       "- **Runway‚Äôs Gen‚Äë4 (Released March 31, 2025)**  \n",
       "  Runway Gen‚Äë4 is a text-to-video generative model, outputting 5‚Äì10 second video clips (720p, 24 fps) from text prompts and reference frames. It emphasizes character consistency, realistic motion, and camera simulation, though consistency across clips remains limited. It‚Äôs available via API and web with subscription-based access.([en.wikipedia.org](https://en.wikipedia.org/wiki/Gen-4_%28AI_image_and_video_model%29?utm_source=openai))\n",
       "\n",
       "- **OpenAI‚Äôs Sora 2 and Sora App (Announced September 30, 2025)**  \n",
       "  On September 30, 2025, OpenAI unveiled Sora 2‚Äîa video/audio generative model‚Äîand a social-style Sora app for sharing short AI-generated clips. The model supports synchronized dialogue, multi-shot consistency, and a feed-centric interface. The launch raised critical concerns around copyright, deepfake regulation, and content moderation.([champaignmagazine.com](https://champaignmagazine.com/2025/10/05/ai-by-ai-weekly-top-5-september-29-october-5-2025/?utm_source=openai))\n",
       "\n",
       "- **DeepMind‚Äôs Genie 3 (Announced Summer 2025)**  \n",
       "  DeepMind introduced Genie 3‚Äîcapable of generating interactive, physics-aware 3D environments‚Äîand releasing them as explorable worlds at real-time frame rates. These environments retain object memory and consistency, acting more like dynamic simulations than static renders‚Äîa noteworthy advance toward AI in game development.([scrumlaunch.com](https://www.scrumlaunch.com/blog/top-5-breakthrough-ai-launches-summer-2025?utm_source=openai))\n",
       "\n",
       "- **Meta‚Äôs AssetGen 2.0 (Announced mid‚ÄëApril 2025)**  \n",
       "  Meta‚Äôs AssetGen 2.0 enhances text- and image-conditioned 3D asset generation via a single-stage 3D diffusion model and a TextureGen component for high-res textures. Initially used in-house, it will soon enable creators on Horizon to generate 3D scenes via prompts.([linkedin.com](https://www.linkedin.com/pulse/top-5-generative-ai-news-updates-from-week-20-2025-11th-shankar-u4wbc?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "##  3. Agentic and Autonomous AI Systems\n",
       "\n",
       "- **Rise of Fully Autonomous AI Agents**  \n",
       "  In 2025, artificial agents evolved from rule-based systems into strategic operators, automating complex tasks like contract negotiation, marketing strategy planning, and even end-to-end product development. These agents adapt dynamically to their environment, fundamentally shifting human-AI collaboration in enterprises.([vocal.media](https://vocal.media/education/5-major-generative-ai-breakthroughs-that-are-shaping-2025?utm_source=openai))\n",
       "\n",
       "- **Anthropic‚Äôs Claude 3.7 ‚ÄúSonnet‚Äù with Hybrid Reasoning Modes**  \n",
       "  Claude 3.7 ‚ÄúSonnet,‚Äù released in early 2025, supports hybrid modes‚Äînear-instant responses or extended reasoning where the model self-reflects step-by-step. Users can control effort vs. speed, with extended reasoning handling up to 128K tokens.([ts2.tech](https://ts2.tech/en/generative-ai-revolution-2025-breakthroughs-industry-disruption-and-predictions-through-2035/?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "##  4. Hardware & Efficiency Improvements\n",
       "\n",
       "- **Model Efficiency, Cost Reduction, & Open-Source Accessibility**  \n",
       "  Innovations in model architecture have made AI more efficient and accessible. Open-source models now challenge proprietary ones, requiring fewer compute resources and benefiting startups and researchers. Synthetic data is widely used for training, improving cost and privacy.([techinnoai.com](https://techinnoai.com/artificial-intelligence-machine-learning/generative-ai-in-2025-breakthroughs-real-world-applications/?utm_source=openai))\n",
       "\n",
       "- **Edge AI and Privacy:**  \n",
       "  Apple, among others, is prioritizing on-device generative AI, integrating features like Genmoji (custom emojis), Visual Intelligence (photo analysis), and enhanced writing tools across iOS/macOS‚Äîsetting trends for privacy-focused AI deployment.([launchconsulting.com](https://www.launchconsulting.com/posts/may-2025-ai-breakthroughs-what-every-business-leader-needs-to-know?utm_source=openai))\n",
       "\n",
       "- **Hardware for Generative AI (Upcoming)**  \n",
       "  Qualcomm announced AI inference accelerators (AI200 and AI250), scheduled for release in 2026 and 2027. These Hexagon-based NPUs support advanced AI workloads with micro-tile inferencing and Gen AI model encryption, targeting improved efficiency and scale in data centers.([tomshardware.com](https://www.tomshardware.com/tech-industry/artificial-intelligence/qualcomm-unveils-ai200-and-ai250-ai-inference-accelerators-hexagon-takes-on-amd-and-nvidia-in-the-booming-data-center-realm?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "##  5. Cross-Domain & Scientific Generative AI\n",
       "\n",
       "- **Diffusion Models for Protein Design**  \n",
       "  A recent research review highlights the role of diffusion models like RFDiffusion in de novo protein design‚Äîsurpassing traditional methods in success rate and reducing experimental cost across over 25 tasks.([arxiv.org](https://arxiv.org/abs/2504.16479?utm_source=openai))\n",
       "\n",
       "- **Generative AI in Multimedia & Semantic Communication**  \n",
       "  Another study introduces a semantic information-theoretic framework for generative multimedia communication. Concepts like semantic entropy and semantic channel capacity were adapted to improve fidelity in human perception, charting future research directions.([arxiv.org](https://arxiv.org/abs/2508.17163?utm_source=openai))\n",
       "\n",
       "- **Reframing Evolutionary Computation as Generative AI (NatGenAI)**  \n",
       "  A new perspective treats evolutionary computation as a form of \"Natural Generative AI,\" allowing exploration beyond training data via search-based, disruptive evolutionary mechanisms, fostering creative generation beyond statistical learning.([arxiv.org](https://arxiv.org/abs/2510.08590?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "##  Summary of Key Themes\n",
       "\n",
       "- The **landscape of generative AI** is evolving rapidly with new models like GPT‚Äë5, Qwen3‚ÄëNext/Omni, Nano Banana, and svelte open-weight variants pushing the frontiers across multimodal, efficient, and localized use.\n",
       "- **Video-, 3D-, and interactive content** generation is gaining momentum through innovations like Runway Gen‚Äë4, Sora 2, Genie 3, and AssetGen 2.0, extending AI from static content to immersive worlds.\n",
       "- **Autonomous AI agents** are becoming strategically operative, as seen in Claude 3.7 and other agentic frameworks.\n",
       "- **Hardware improvements** and **efficiency**‚Äîfrom edge AI on devices to high-performance data center cores‚Äîstrengthen the infrastructure supporting generative systems.\n",
       "- **Scientific and theoretical advances** expand generative AI‚Äôs reach into molecular biology, semantic communication, and algorithmic innovation.\n",
       "\n",
       "---\n",
       "\n",
       "In conclusion, **as of November 2025**, generative AI is experiencing an extraordinary surge in capacity, accessibility, and application range‚Äîfrom deep reasoning and creativity to real-time interaction and scientific discovery. Let me know if you'd like a deeper dive into any of these developments!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(web_search_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85df607-d638-4d58-99a8-99a6cfe2d7e8",
   "metadata": {},
   "source": [
    "### Stateful Response\n",
    "\n",
    "The OpenAI Responses API includes a stateful feature that enables continuity in interactions. \n",
    "By using the `response_id`, a conversation can persist across multiple queries, \n",
    "allowing users to refine or expand upon previous searches. This is particularly useful for iterative research, \n",
    "dynamic content generation, and applications that require follow-up queries based on prior responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b3e83a4-3437-4e9f-9732-748a35ccd43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here‚Äôs a comprehensive, up-to-date overview of the **latest developments in generative AI as of Nove"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fetched_response = client.responses.retrieve(response_id=web_search_response.id)\n",
    "display(Markdown(fetched_response.output_text[:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ca4d4-b2f7-4cd2-94b6-a0d2aec179cb",
   "metadata": {},
   "source": [
    "### Continue Query with Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b348e31e-3aea-4656-b86e-b0f62ef9c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_query = 'find different news'\n",
    "\n",
    "continue_search_response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input= continue_query,\n",
    "    previous_response_id=web_search_response.id,\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3ecd050-c5e3-44ca-869b-657e90aca446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are several **recent and diverse developments in generative AI**, drawing on trusted news sources. Each paragraph includes at least two citations and is structured for clarity and depth.\n",
       "\n",
       "‚Äî\n",
       "\n",
       "Google‚Äôs push to support enterprise AI environments continues to deepen. Just a few days ago, Google announced enhancements to its **Vertex‚ÄØAI Agent Builder**, introducing new observability and deployment tools designed to help companies deploy AI agents more reliably and at scale. This move strengthens Google's competitive position against Microsoft and AWS in the enterprise AI market([infoworld.com](https://www.infoworld.com/article/4085736/google-boosts-vertex-ai-agent-builder-with-new-observability-and-deployment-tools.html?utm_source=openai)).\n",
       "\n",
       "‚Äî\n",
       "\n",
       "Meanwhile, the **semiconductor industry** is experiencing what many are calling a ‚Äúsilicon supercycle.‚Äù Driven by surging demand for generative AI workloads, data centers are driving unprecedented demand for cutting-edge chips. As a result, chipmakers find themselves at a pivotal growth inflection point reshaping the global technology and economic landscape([markets.financialcontent.com](https://markets.financialcontent.com/wral/article/tokenring-2025-11-10-the-silicon-supercycle-how-ai-data-centers-are-forging-a-new-era-for-semiconductors?utm_source=openai)).\n",
       "\n",
       "‚Äî\n",
       "\n",
       "In the pharmaceutical and biotech arena, **Insilico Medicine** unveiled a breakthrough in generative AI-powered drug discovery. On November‚ÄØ7,‚ÄØ2025, the company announced a portfolio of newly discovered cardiometabolic disease molecules developed using generative AI models‚Äîmarking a significant stride in clinical-stage AI innovation([eurekalert.org](https://www.eurekalert.org/news-releases/1105110?utm_source=openai)).\n",
       "\n",
       "‚Äî\n",
       "\n",
       "Over in academia, **the University of Sydney‚Äôs Informatics Hub** is helping Australia's researchers adopt generative AI tools more effectively. This initiative provides guidance and frameworks for researchers navigating the expanding‚Äîbut potentially risky‚Äîopportunities generative AI presents in academia([sydney.edu.au](https://www.sydney.edu.au/news-opinion/news/2025/11/04/sydney-informatics-hub-unlocks-generative-ai-for-research.html?utm_source=openai)).\n",
       "\n",
       "‚Äî\n",
       "\n",
       "Across the Atlantic, experts in the **UK are sounding an alarm** over a new societal side-effect: \"AI-powered nimbyism.\" Advanced scanning tools are increasingly being used by citizens to identify grounds for objecting to planning applications, potentially undermining government housebuilding efforts([theguardian.com](https://www.theguardian.com/politics/2025/nov/09/ai-powered-nimbyism-could-grind-uk-planning-system-to-a-halt-experts-warn?utm_source=openai)).\n",
       "\n",
       "‚Äî\n",
       "\n",
       "These developments span enterprise deployment tools, semiconductor market dynamics, drug discovery, academic adoption, and societal implications of AI‚Äîreflecting the breadth and complexity of generative AI‚Äôs current impact. If you‚Äôd like a detailed deep dive into any of these themes‚Äîor to explore additional fronts like model launches, regulation, or global competition‚Äîjust say the word!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(continue_search_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132125be-48d9-4596-9dc5-bc12dca5fdbf",
   "metadata": {},
   "source": [
    "### Combining File Search and Web Search\n",
    "\n",
    "This is an example of using file search to analyze private data and web search to retrieve public or the latest data. \n",
    "The Responses API allows developers to integrate these tools to enhance retrieval-augmented generation (RAG) applications. \n",
    "By combining file search with web search, users can leverage structured internal knowledge while also retrieving real-time \n",
    "information from external sources, ensuring comprehensive and up-to-date responses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6344e43c-8aa4-4693-aaf6-20f09f416364",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_search_response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input= query,\n",
    "    temperature = 0,\n",
    "    instructions=\"Retrieve the results from the file search first, and use the web search tool to expand the results with news resources\",\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store_id],\n",
    "    },\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a09ee0a6-3b50-43a3-a63b-3c765da85561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here‚Äôs a comprehensive and up-to-date overview of the **latest developments in generative AI** as of **November 10, 2025**, with detailed citations and structured analysis:\n",
       "\n",
       "---\n",
       "\n",
       "##  Major Model Releases and Enhancements\n",
       "\n",
       "- **OpenAI GPT‚Äë5**  \n",
       "  Released on **August 7, 2025**, GPT‚Äë5 is a multimodal foundation model accessible via ChatGPT and Microsoft Copilot, offering state-of-the-art performance across text, image, and reasoning tasks ([en.wikipedia.org](https://en.wikipedia.org/wiki/GPT-5?utm_source=openai)).  \n",
       "  It features a massive **256,000-token context window**, a ‚Äúthinking mode‚Äù for planning and error correction, and seamless integration of text, image, and voice modalities. Early benchmarks show it outperforms GPT‚Äë4 by over 40% on complex logical reasoning tasks ([scrumlaunch.com](https://www.scrumlaunch.com/blog/top-5-breakthrough-ai-launches-summer-2025?utm_source=openai)).\n",
       "\n",
       "- **OpenAI o4‚Äëmini**  \n",
       "  Launched on **April 16, 2025**, this lightweight, multimodal reasoning model supports both text and image inputs, including whiteboard sketch analysis and chain-of-thought reasoning. A higher-accuracy variant, o4‚Äëmini‚Äëhigh, is available to paid users ([en.wikipedia.org](https://en.wikipedia.org/wiki/OpenAI_o4-mini?utm_source=openai)).\n",
       "\n",
       "- **OpenAI GPT‚Äë4.1**  \n",
       "  Released on **April 14, 2025**, GPT‚Äë4.1 (along with mini and nano variants) focuses on improved coding capabilities and is available via API and ChatGPT Plus/Pro tiers ([en.wikipedia.org](https://en.wikipedia.org/wiki/GPT-4.1?utm_source=openai)).\n",
       "\n",
       "- **Anthropic Claude 3.7 Sonnet**  \n",
       "  Introduced in **February 2025**, this hybrid reasoning model includes an ‚Äúextended thinking mode‚Äù that enables self-reflection before responding, improving performance in math, physics, coding, and instruction-following tasks. It‚Äôs available across all Claude plans, with extended thinking reserved for paid tiers ([reuters.com](https://www.reuters.com/technology/artificial-intelligence/anthropic-launches-advanced-ai-hybrid-reasoning-model-2025-02-24/?utm_source=openai)).\n",
       "\n",
       "- **OpenAI gpt‚Äëoss‚Äë120b and gpt‚Äëoss‚Äë20b**  \n",
       "  Released in **August 2025**, these are OpenAI‚Äôs first open-weight models since GPT‚Äë2. They support chain-of-thought reasoning and can run locally‚Äîgpt‚Äëoss‚Äë20b on consumer hardware (e.g., PCs with 16‚ÄØGB RAM or Snapdragon processors), and gpt‚Äëoss‚Äë120b on more powerful setups like NVIDIA RTX GPUs ([windowscentral.com](https://www.windowscentral.com/artificial-intelligence/openai-chatgpt/openai-launches-two-gpt-models-theyre-not-gpt-5-but-they-run-locally-on-snapdragon-pcs-and-nvidia-rtx-gpus?utm_source=openai)).  \n",
       "  AWS has made these models available via Bedrock and SageMaker, offering significant cost-efficiency‚Äîthree times cheaper than Gemini, five times cheaper than DeepSeek‚ÄëR1, and twice as efficient as OpenAI‚Äôs o4 model ([timesofindia.indiatimes.com](https://timesofindia.indiatimes.com/technology/tech-news/amazon-announces-first-ever-availability-of-openai-models-for-its-cloud-customers-company-says-the-addition-of-/articleshow/123125170.cms?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "##  Google DeepMind and Gemini Ecosystem\n",
       "\n",
       "- **Gemini 2.5 Pro & Flash**  \n",
       "  Google‚Äôs most advanced models, Gemini 2.5 Pro and Flash, were released in early 2025. Gemini 2.5 Pro features enhanced reasoning, coding, and a ‚ÄúDeep Think‚Äù mode for complex tasks, while Flash offers faster responses. Both support native audio output and improved security ([en.wikipedia.org](https://en.wikipedia.org/wiki/Gemini_%28language_model%29?utm_source=openai)).\n",
       "\n",
       "- **Nano Banana (Gemini 2.5 Flash Image)**  \n",
       "  Launched on **August 26, 2025**, this image generation and editing model went viral for its photorealistic ‚Äú3D figurine‚Äù outputs. It supports subject consistency, multi-image fusion, and includes SynthID watermarking for AI-generated content identification. It quickly attracted over 10 million new users and facilitated more than 200 million image edits ([en.wikipedia.org](https://en.wikipedia.org/wiki/Nano_Banana?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "##  Multimedia and Creative AI Innovations\n",
       "\n",
       "- **Veo 3 (Google)**  \n",
       "  Released in **June 2025**, Veo 3 is a text-to-video model that generates video with synchronized sound effects, ambient noise, and dialogue‚Äîeliminating a major post-production hurdle ([aiinsight.blog](https://aiinsight.blog/generative-ai-advancements-in-2025?utm_source=openai)).\n",
       "\n",
       "- **OpenAI Sora**  \n",
       "  Integrated into ChatGPT for Plus users in **May 2025**, Sora enables conversational video generation, allowing users to refine visual outputs within the chat interface ([aiinsight.blog](https://aiinsight.blog/generative-ai-advancements-in-2025?utm_source=openai)).\n",
       "\n",
       "- **Midjourney V7**  \n",
       "  Launched in **May 2025**, this update introduces ‚ÄúNeRF-like‚Äù 3D model generation and text-to-video capabilities, offering artists a unified workflow for still images, video, and 3D assets ([aiinsight.blog](https://aiinsight.blog/generative-ai-advancements-in-2025?utm_source=openai)).\n",
       "\n",
       "- **Runway Gen‚Äë4**  \n",
       "  Released in **April 2025**, Gen‚Äë4 includes a ‚ÄúCharacter Lock‚Äù feature that maintains a character‚Äôs appearance across multiple generated scenes‚Äîhighly requested by creators ([aiinsight.blog](https://aiinsight.blog/generative-ai-advancements-in-2025?utm_source=openai)).\n",
       "\n",
       "- **Stability AI Stable Audio 2.0**  \n",
       "  Released in **March 2025**, this update enables generation of longer, more coherent musical pieces (up to five minutes), with advanced controls for structure, instrumentation, and emotional tone ([aiinsight.blog](https://aiinsight.blog/generative-ai-advancements-in-2025?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "##  Broader Trends and Infrastructure\n",
       "\n",
       "- **Unified Multimodal Models**  \n",
       "  2025 has seen a shift toward models that seamlessly handle text, image, video, and audio in a unified architecture‚Äîimproving efficiency and context-awareness ([aiinsight.blog](https://aiinsight.blog/generative-ai-advancements-in-2025?utm_source=openai)).\n",
       "\n",
       "- **Open-Source and Efficient Models**  \n",
       "  Open-source models like Hugging Face‚Äôs SmolLM3 (3B parameters, 128K context window) and Liquid AI‚Äôs LFM2 series (350M‚Äì1.2B parameters) are gaining traction for their efficiency, accessibility, and strong performance ([linkedin.com](https://www.linkedin.com/pulse/top-generative-ai-updates-week-july-2-2025-kalyan-ks-oorrc?utm_source=openai)).\n",
       "\n",
       "- **Agentic AI and Autonomous Agents**  \n",
       "  Generative AI is evolving toward fully autonomous agents capable of strategic decision-making, adapting to feedback, and managing complex tasks independently‚Äîtransforming how businesses operate ([vocal.media](https://vocal.media/education/5-major-generative-ai-breakthroughs-that-are-shaping-2025?utm_source=openai)).\n",
       "\n",
       "- **Hardware and Infrastructure Advances**  \n",
       "  Qualcomm recently announced its AI200 and AI250 inference accelerators, targeting data center workloads with features like micro-tile inferencing, Gen AI model encryption, and high memory capacity. These are slated for release in 2026 and 2027 ([tomshardware.com](https://www.tomshardware.com/tech-industry/artificial-intelligence/qualcomm-unveils-ai200-and-ai250-ai-inference-accelerators-hexagon-takes-on-amd-and-nvidia-in-the-booming-data-center-realm?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "##  Summary Table\n",
       "\n",
       "| Category                  | Key Developments                                                                 |\n",
       "|---------------------------|----------------------------------------------------------------------------------|\n",
       "| **Large Language Models** | GPT‚Äë5, o4‚Äëmini, GPT‚Äë4.1, Claude 3.7 Sonnet, gpt‚Äëoss models                        |\n",
       "| **Multimodal & Creative** | Gemini 2.5 Pro/Flash, Nano Banana, Veo 3, Sora, Midjourney V7, Runway Gen‚Äë4      |\n",
       "| **Open-Source & Efficiency** | SmolLM3, LFM2 series, open-weight gpt‚Äëoss models                              |\n",
       "| **Agentic AI**            | Autonomous agents with strategic capabilities                                   |\n",
       "| **Infrastructure**        | Qualcomm AI200/AI250 accelerators                                               |\n",
       "\n",
       "---\n",
       "\n",
       "##  Final Thoughts\n",
       "\n",
       "As of **November 10, 2025**, generative AI is advancing rapidly across multiple dimensions:\n",
       "\n",
       "- **Multimodality** is becoming the norm, with models like GPT‚Äë5 and Gemini 2.5 handling text, image, audio, and video seamlessly.\n",
       "- **Reasoning and autonomy** are central, with models like Claude 3.7 Sonnet and GPT‚Äë5‚Äôs thinking mode enabling deeper, more reliable outputs.\n",
       "- **Accessibility** is improving through open-weight models and efficient open-source alternatives.\n",
       "- **Creative tools** are maturing, enabling video, 3D, and audio generation with unprecedented ease.\n",
       "- **Hardware innovation** is keeping pace, ensuring that infrastructure can support these powerful models.\n",
       "\n",
       "Let me know if you'd like a deeper dive into any specific model, company, or application area!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(combined_search_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cac39c8-d345-4faf-a98f-2301b96e80a2",
   "metadata": {},
   "source": [
    "# üß© Try It Yourself: Two-Step RAG (Private Data + Combined Search)\n",
    "\n",
    "## Step 1 ‚Äî Upload & Create Vector Store\n",
    "1. Upload a short text file (e.g., `my_notes.txt`) to your notebook instance.  \n",
    "2. Create a **vector store** and **ingest** your uploaded file.  \n",
    "3. Run a simple test query to verify retrieval:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9eedf50-48f8-4092-bb20-c150f3848671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs_69126be4ff48819187617bd0a994b745\n",
      "file-DfRnmBBdrsw7Zwfz5LEQ83\n",
      "file-DfRnmBBdrsw7Zwfz5LEQ83\n"
     ]
    }
   ],
   "source": [
    "vector_store = client.vector_stores.create(\n",
    "    name=\"my_vector_store\"\n",
    ")\n",
    "vector_store_id = vector_store.id\n",
    "print(vector_store_id)\n",
    "\n",
    "with open('Intel Report MLAI.txt', 'rb') as f:\n",
    "    file = client.files.create(\n",
    "        file=f,            # file-like object\n",
    "        purpose=\"assistants\"\n",
    "    )\n",
    "\n",
    "file_id = file.id\n",
    "print(file_id)\n",
    "\n",
    "attach_status =client.vector_stores.files.create(\n",
    "    vector_store_id=vector_store_id,\n",
    "    file_id=file_id\n",
    "            )\n",
    "\n",
    "print(attach_status.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a082eab-344f-4fac-9b61-d523ad1da53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is the article about?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3622a2e-f678-4bcd-8427-25f021d45855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "\n",
      "Since the December 2024 collapse of the government of Bashar Al Asad, Syrians have pursue\n",
      " Relevant score: 0.4050559436347581\n",
      "security support since 2015. The SDF remains the principal U.S. partner in the fight against the Isl\n",
      " Relevant score: 0.3629165098590976\n"
     ]
    }
   ],
   "source": [
    "search_results = client.vector_stores.search(\n",
    "    vector_store_id=vector_store_id,\n",
    "    query=query\n",
    ")\n",
    "\n",
    "for result in search_results.data[:5]:\n",
    "    print(result.content[0].text[:100] + '\\n Relevant score: ' + str(result.score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c43361-5d0a-4aaf-9476-edada3f1e521",
   "metadata": {},
   "source": [
    "## Step 2 ‚Äî Combine File Search with Web Search\n",
    "1. Enable both **file_search** and **web_search** in the Responses API.  \n",
    "2. Use a prompt that asks the model to merge insights from both sources.  \n",
    "   > Example: ‚ÄúUsing my uploaded notes and the latest web information, summarize the current trends on this topic.‚Äù  \n",
    "3. Review how the answer from your file and **current info** from the web.\n",
    "\n",
    "‚úÖ You‚Äôve created a RAG system that combines **private** and **public** data for comprehensive, up-to-date analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1b9195a-b8b0-453e-b1fd-933fc5f154fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_response = client.responses.create(\n",
    "  model=\"gpt-4o\",\n",
    "  input=[\n",
    "      {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": query\n",
    "      }\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f3ce884-72ff-4ca8-9e7d-f1b16463c044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure, I can help with that. Could you provide some details or key points from the article?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(simple_response.output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5de79651-e634-4b4a-ab0a-d2062dfbc9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_search_response = client.responses.create(\n",
    "    input= query,\n",
    "    model=\"gpt-4o\",\n",
    "    temperature = 0,\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store_id],\n",
    "    }]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91a6d4ea-3037-4941-97ad-31655a927632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The article discusses the situation in Syria following the collapse of Bashar Al Asad's government in December 2024. It covers the political and economic opportunities that have arisen, as well as the challenges posed by internal tensions and external pressures. The interim government, led by Ahmed Al Sharaa, is working on a transitional constitutional framework and planning elections. However, the government does not control all of Syria, with various regions under different authorities, including Kurdish-led forces and Druze communities. The article also touches on the involvement of neighboring countries like Turkey and Israel, and the role of the United States and European Union in supporting the interim government through sanctions relief and dialogue with Kurdish forces."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(file_search_response.output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59c39ddd-0389-4dd5-bde5-33d0ffc98b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search_response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input= query,\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb42ffbb-f422-49f3-9d4d-e1f6f3188d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Could you please specify which article you're referring to or provide more details about it?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(web_search_response.output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8abbf6b3-f77c-4e31-8057-3b2815143845",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_search_response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input= query,\n",
    "    temperature = 0,\n",
    "    instructions=\"Using my uploaded notes and the latest web information, summarize the current trends on this topic.\",\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store_id],\n",
    "    },\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce6a056c-88fc-48ea-9447-924e03630c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The article discusses the situation in Syria following the collapse of Bashar Al Asad's government in December 2024. It highlights the political and economic opportunities that have emerged, as well as the challenges posed by internal tensions and external pressures. The interim government, led by Ahmed Al Sharaa, is navigating a complex transition with plans for elections and a new constitutional framework. However, the government struggles to maintain control over the entire country, with various regions under different authorities, including Kurdish-led forces and Druze communities. The involvement of foreign powers like Turkey and Israel further complicates the situation. The U.S. and EU have extended sanctions relief to support the interim government, but economic recovery is hindered by longstanding issues."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(combined_search_response.output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb09266a-54fc-46bb-b872-d88a0d456394",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
